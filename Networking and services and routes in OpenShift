Introduction to OpenShift :
===========================
Today we will look at networking in OpenShift.
Let's Quickly recap the basics of networking in k8s so that we can easily relate it to networking in OpenShift.
  > A k8s cluster, As we know, is composed of a master and worker nodes.
  > Since each of these are virtual or physical machines, They all have their own IP addresses.
    > Let's say, 192.168.1.10(Master), 192.168.1.11(Worker1), 192.168.1.12(Worker2), 192.168.1.13(Worker3).
  > When application is deployed on this cluster in the form of Docker container in Pods, Each pod gets an IP address assigned to it.
  > Now these pods could be running  different types of applications dependent on each other.
  > For example, The first one maybe running a web server and the second maybe running a database server.
    So a fundamental requirement is for the Pods to be able to communicate with each other. For this to happen, The pods must be on a network configured in a way where they can communicate with each other and have unique IP addresses.
    So, Who is responsble for assigning these ip addresses and managing them ? Making sure each pod gets unique IP address and ensure routes are in place to direct traffic between the differnt worker nodes ?
       > Openshft solves this problem using the OpenShift software defined Networking. 
       > The Open shift software defined network creates a virtual network that spans across multiple nodes in the cluster. 
       > This virtual network is called an overlay network. And is created using the Open vSwitch standard.
          > Open vSwitch is a distributed virtual switch used to interconnect virtual machine is a Hypervisor.
          > Some of it's features include VLAN tagging, Trunking, LACP, Port mirroring, & etc.
       > The default network ID for the overlay network is 10.128.0.0/14. On this network, Each node is addigned a unique subnet, Such as 10.128.0.0 for the first node, 10.128.2.0 for the second node,  10.128.4.0 for the third node.
       > All pods on these nodes now get a unique IP address within that subnet. 
       > The web application now has the IP address 10.128.0.5 and the database gets 10.128.2.2
       > We can see the IP addresses assigned to each POD when you run the "oc get pods -0 wide" command.
       > The web application can now connect to the database this IP address. 
       > However, Establising connectivity to another pod with its ip address may not be a good idea. As it's not guaranteed to be the same each time. If the database POD was restarted, It may have a new IP address. For this reason, OpenShift has a built-in DNS server.
       > The DNS server helps map IP addresses to PODs and services. This enable us to use a POD name or service name to connect to the database instead of IP addresses. 
       > OpenShift DNS leverages sky DNS to implement DNS functionality on top of ETCD. 
         Note that establishing connectivity between PODs directly is not recommended.
       > The recommended way is to use services.
       > Openshift software defined networking provides different kinds of plugins, The default plugin configured is the ovs-subnet that provides network connectivity between all pods across clusters.
       > Additionally openshift also supports additional plugins such as "nuagenetworks", "Contiv", And "Flannel". Each of these has it's own way of networking and pros and cons that works best for different requirments.
    So far, We discussed about overlay networks that facilitate internal communication between PODs and services.
    But, What about external connectivity ? How can we users access our application ? 
    ---------------------------------------------------------------------------------
       That's achived with the help of services and routes,

# services concept in Networking :
==================================
   We are going to quick recap what services are.
   If you have gone through the concept of services in k8s, This is the same in OpenShift.
 We will quickly recap the basics and then, See how we can work with services in OpenShift.
 ------------------------------------------------------------------------------------------
   > Services help connect different applications or group of pods with one another.
   > Instead of relying on the IP Address or DNS name of a POD, it is recommended to use a service as a service acts as a load balancer for each section of our microservices architecture.
   > For ex : we have front-end -> back-end -> Data processing microservices.
   > In this case, The front-end talks to the backend thriugh a service. And the back-end talks to a dataprocessing application through a service. 
   > The front-end can expose our application to the end users, again, through a service.
   > And in case we need access to an external data stores, Again, It's accomplished with the help of services.
   > Services provides us with the flexibility of modifying and redeploying the underlying microservices without having to worry about modifying configuartion of other dependent applications.
   > Each service within Openshift gets it's own IP address and DNS entries, That can be used to establish connectivity from other applications. 
   > Like pods each service gets an internal IP address assigned, This is called Cluster IP because it is the IP assigned to the service for internal communication within the cluster.
   > It can be seen in the UI next to the list of services.
But How are services linked to Pods ?
--------------------------------------
   > We link services to the pods by using selectors.
   > To link the service to all the pods created by the sample-webapp-docker(existing) deployment we use selectors in the deploymentconfig file( like deploymentconfig=sample-webapp-docker(existing deploymentname))
   > Then we also specify the port on the service to listen to and the target port on the pods to forward the request to.
   > These can be seen in the user interface under the service details: 
        > The selector, Service port and target port.
   > However, We have only linked the service to the backend pods.
How do we make it accessible to external users ?
-------------------------------------------------
   > The users would like to access our application usinga host name like (www.somewebapp.com), That's where routes comming.
   > A route helps us expose the service to external users through a host name. 
   > Think of a route as a proxy server, Such as HA proxy or F5. 
   > We can configure loadbalancing, security, as well as split between services with routes. The route is responsible for balancing load across the diffent pds within the deployment.
   > In order to do that,  It relies on
   > Different loadbalancing strategies such as :
    ---------------------------------------------
      1. source strategy, 
      2. Roundrobin strategy,
      3. leastcinn strategy.
   1. Source strategy : 
   --------------------
      This is the default strategy used. 
      This source strategy looks at the IP address of the user, accessing the application and make sure that user is always direct to the same back-end server for the duration of that session, Thus providing a sticky session functionality.
   2. Roundrobin strategy :
   ------------------------
      In this strategy, Each request is directed to a seperate back-end pod each time, Even if the requests originate from the same user IP address. 
   3. leastcinn strategy :
   -----------------------
       In this strategy, This routes traffic to the endpoint with the lowest number of connections.
Security :
----------
    > Under the security section, We can configure ssl security, So the web application can be accessed using https. 
    > Also under the insecure traffic section, Decide whether you would like to allow the users to access your site using http or redirect the users to the https version of the site automatically when they try to access http. 
    > We may also configure the certificates and private keys in the same section.
    > Routes also allow us to split traffic between 2 services for A/B testing purposes.
    > The alternative services section in the UI splits traffic between 2 services in this case. It is as easy as moving the slider in the direction we wish to go based on test results.


Demo for services and routes :
==============================
> In this demo we will look at services and routes. Till now we have now configured build and deployments for our application.
> The next step is to expose it to other applications or external users. 
> To Make the application accessible to other applications within the cluster, we create a service.
> To get a template for the service configuration file, 
    > Go to openshift UI > Click on applications > choose services tab in options > Click on learn more link.()
> Copy the yaml config.
apiVersion: v1
kind: Service
metadata:
  name: frontend      
spec:
  selector:                  
    deploymentconfig=frontend # The selctor links the service to the pods hosting the application, You can change this selctor according to your deployment config.
  clusterIP: 172.30.136.123   # The cluster IP is the IP assigned to the service, During service creation, An IP is assigned automatically, So we will get rid of that line.  
  ports:                      # The port section defined what port to listen on and what port to forward the traffic to.
  - nodePort: 0
    port: 5000               
    protocol: TCP
    targetPort: 5000   
> We know the application listens on 8080, So we use that. Once the file is ready.
> Go to your Openshift UI
> Go to your project
> Go to apllications
> Choose services
> Choose add to project
> Choose import YAML/Json
> Paste the modified service yaml
> click on create to create a service.
> Now, click on the newly created service to view it.
> We see that is has an IP address assigned to it automatically.
> Which happens to be 172.30.163.74
> Click on the newly created service, and now you can see more details about your service(like selector, type, ip, hostname. routes & etc).
> Now we can access our application through the service using assigned IP in service.
  > This is, However, an internal cluster IP address which can't be accessed externally.
  > But let's try to access it internally.
  > Access the console of the openshift cluster,
  > And run the curl command using the IP address and port to see the application
     "curl http://172.20.163.74:8080".
  > It returns successful output.

# Now we will create a Route to access the application externally :
===================================================================
   We can do this using yaml-based method, As we have been doing so far in the demos.
   > Click on "create a route" option inside your service under routes option.
   > Clicking on the link takes us to the "create route form" 
   > Fill in the details (like name, Hostname, path, service, Target port, Alternative services) 
      > In this example demo we will leaving the hostname blank will generate a hostname for us based on the application name.
      > A quock note on host names. If you need to use another host name here such as www.example.com, 
      > You need to make sure that the external DNS is configured to route users to the OpenShift cluster when they try to access the url.
      > Once they land on OpenShift cluster, The route configured in OpenShift will ensure they are redirected to the right application based on the hostname.
   > We will leave everything else to default and create the route, Click on create.
   > Once the route is created we can see the generated hostname.
   > Click on this hostname link, Takes us to the application on browser.

# Let's run the end to end test now :
======================================
   > When we do a change in our code repo, It automatically triggers a new build. 
   > Once the build is completed (You can see the details on openui dashboard under builds section), A new deployment is triggered.
   > And once the deployment is complete, The changes code is reflected in the application UI, When the browser is refreshed.
   



